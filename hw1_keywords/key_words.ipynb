{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE\n",
    "import nltk\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords as kw_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename):\n",
    "    with open (filename, encoding = 'utf-8') as f:\n",
    "        content = f.read()\n",
    "    key_words, my_key_words, text = content.split('\\n\\n\\n')\n",
    "    return key_words.strip('\\ufeff').split('\\n'), my_key_words.split('\\n'), text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(t)[0].normal_form\n",
    "        )\n",
    "    return ' '.join(lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты для моего мини-корпуса взяты с сайта НИУ ВШЭ (раздел \"Новости\"), где ключевые слова помечены как \"темы\", есть еще отдельная метка \"рубрика\" - ее содержание не включалось в список ключевых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ('control.txt', 'vvp.txt', 'career_marathon.txt', 'social.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for text control.txt\n",
      "Precision 0.4 \n",
      "Recall 0.16666666666666666 \n",
      " F1 0.23529411764705882 \n",
      "\n",
      "REAL KEY WORDS\n",
      " ['лектории', 'Университет, открытый городу', 'новое в ВШЭ', 'приглашение к участию']\n",
      "PREDICTED\n",
      " rake ['акция « выходить решать', 'сбор участник', 'контрольный', 'физика', 'информатика', 'корпус', 'ауд', '»', '11', '10', '30', '00'] \n",
      " textrank ['контрольныи', 'она'] \n",
      " tf-idf ['на', '00', 'контрольной', '10', 'ауд'] \n",
      "\n",
      "Results for text vvp.txt\n",
      "Precision 0.0 \n",
      "Recall 0.0 \n",
      " F1 0 \n",
      "\n",
      "REAL KEY WORDS\n",
      " ['цифра дня', 'исследования и аналитика', 'экспертиза', 'статистические данные']\n",
      "PREDICTED\n",
      " rake ['8 миллиард рубль', 'это', '3', '5 %', '1', '1 %', '2 %', '0'] \n",
      " textrank ['цифровои', 'миллиард', 'исиэз', 'год', 'триллион рубль', 'исследование', 'потратить', 'внутреннии затрата'] \n",
      " tf-idf ['на', 'руб', 'млрд', 'трлн'] \n",
      "\n",
      "Results for text career_marathon.txt\n",
      "Precision 0.25 \n",
      "Recall 0.2 \n",
      " F1 0.22222222222222224 \n",
      "\n",
      "REAL KEY WORDS\n",
      " ['выпускники', 'студенты', 'карьерный марафон', 'ярмарка вакансий']\n",
      "PREDICTED\n",
      " rake ['hse career marathon', 'стажировка', 'студент', 'работать', '«'] \n",
      " textrank ['стажировка для студент', 'ярмарка', 'весь', 'говорить'] \n",
      " tf-idf ['на', 'для'] \n",
      "\n",
      "Results for text social.txt\n",
      "Precision 0.0 \n",
      "Recall 0.0 \n",
      " F1 0 \n",
      "\n",
      "REAL KEY WORDS\n",
      " ['идеи и опыт', 'студенты', 'предпринимательство в социальной сфере', 'социальные инновации']\n",
      "PREDICTED\n",
      " rake ['социальный предпринимательство “ социальный инновация', 'организация доступный среда', 'маломобильный группа население'] \n",
      " textrank ['социальныи', 'слушатель программа', 'вшэ', 'михаил киселев', 'для', 'организация', 'свои проект', 'год'] \n",
      " tf-idf ['проект'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    key_words, my_key_words, text = get_text(file)\n",
    "    \n",
    "    #rake\n",
    "    kw_list = rake.run(normalize_text(text), maxWords=5, minFrequency=2)\n",
    "    kw_rake = [x[0] for x in kw_list]\n",
    "    \n",
    "    #TextRank\n",
    "    kw_gensim = kw_gs(normalize_text(text), pos_filter=[], scores=True)\n",
    "    kw_gensim = [x[0] for x in kw_gensim if x[1]>0.15]\n",
    "    \n",
    "    #tf-idf\n",
    "    corpus = sent_tokenize(text)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    scores = zip(vectorizer.get_feature_names(), np.asarray(X.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    tf_list = [x[0] for x in sorted_scores if x[1]>1]\n",
    "    \n",
    "    #precision, recall, f1\n",
    "    print('Results for text', file)\n",
    "    precision = len(set(kw_rake).intersection(set(my_key_words)))/len(my_key_words)\n",
    "    recall = len(set(kw_rake).intersection(set(my_key_words)))/len(kw_rake)\n",
    "    if precision != 0 and recall != 0:\n",
    "        f1 = 2*(recall*precision)/(recall+precision)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    print('Precision', precision, '\\n'\n",
    "         'Recall', recall, '\\n',\n",
    "         'F1', f1, '\\n')\n",
    "    print ('REAL KEY WORDS\\n', key_words)\n",
    "    print('PREDICTED\\n',\n",
    "          'rake', kw_rake, '\\n',\n",
    "         'textrank', kw_gensim, '\\n',\n",
    "          'tf-idf', tf_list,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В статье с большим количеством числительных они выделяются в качестве ключевых слов. Также выделяются именна собственные, тут, кажется, зависит от того, что мы хотим видеть в ключевых словах, в принципе, они могут быть полезными.Есть также проблема с переводом названий (наверняка то же случится с географическими названиями), например, 'career marathon' и 'карьерный марафон' на самом деле одно и то же! Кажется, что нужна какая-то база подобных соответствий. Некоторые выражения, являющиеся ключевыми словами, не распознаются, но слова, входящие в их состав, алгоритм определяет как ключевые. Как решить эту проблему мне пока непонятно, ведь установить распознавание ключевых выражений длиной 3, допустим, мы не можем, а определение коридора длины проблему не решит.\n",
    "В целом, основная проблема заключается в преобработке текста, нужно усовершенствовать токенизацию, убирать цифры, расширить список стоп-слов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
